## 🧠 Using Long-Term Memory (LTM) in this project
This project supports Long-Term Memory (LTM) to enable AI to “remember” or “reference” past conversations/data accurately (e.g. previous conversations, data in databases, documents embedded in Vector Store, etc.), which allows the system to respond intelligently and consistently.

## 💡 What is LTM?
Long-Term Memory here means storing important data for a long time (e.g. conversations, text, references, embeddings) in a database such as MongoDB or Pinecone to be reused and linking previous knowledge to what the AI ​​is interacting with.

## 🛠️ How to use LTM in this project
1. Prepare the environment
You must set the correct Environment Variables (MONGO_URL, PINECONE_API_KEY, etc.)

See the settings details in the "Getting Started" topic above.

2. How it works
When AI receives new input (e.g. questions from users)
→ The system will pull the relevant context from LTM (MongoDB/Pinecone)
→ The AI ​​analyzes that context and responds in a way that is consistent with what the user has said or asked.

3. Sample workflow
Embedding

When uploading files/conversations Data is generated by an Embedding and stored in a Vector Store (e.g. Pinecone).

Pull context

When a user asks a question, the system uses the question's Embedding to search for the closest context from the Vector Store or database.

Answers by referencing prior knowledge

The AI ​​combines the found context with the prompt to generate an answer.

4. Related important code files
embed_MongoDB.py / retrival_MongoDB.py
For handling Embedding and Retrieval from MongoDB

embed_pinecone.py / retrival_Pinecone.py
For Embedding and Retrieval from Pinecone

Prompt.py
Format the prompt/context to be sent to LLM

## 🐍 Python Version
Python: 3.13.x

## 🚀 Getting Started
🛠️ 1. Create an Environment
```python -m venv venv```

📦 2. Install the Library via the environment
```pip install -r requirements.txt```

🔐 3. Set the Environment Variables
Create a .env file inside the venv/ folder Then add the values:

<pre>OPENAI_API_KEY=your_openai_api_key
MONGO_URL=your_localhost_or_remote_url
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENV=your_pinecone_environment
EMBEDDING=embedding_model_name_from_openai
FACEBOOK_ACCESS_TOKEN=TOKEN_API_FACEBOOK
HF_TOKEN=your_huggingface_token
TYPHOON_API_KEY=your_key
TYPHOON_API_URL=https://api.opentyphoon.ai/v1
</pre>

You can get the typhoon api key from https://playground.opentyphoon.ai/api-key

## 🧪 How to run the project
▶️ Run the Backend (FastAPI)
```cd main_backend```

```uvicorn main:app --reload --port 8000```

## Alternative run frontend 

## 🖼️ Run Frontend (Streamlit)
Open a new Terminal:
```cd frontend```

```streamlit run app.py```
## 🖼️ Run Frontend (Prototype)
```cd frontend```

```npm run dev```

## 🛠️ Fix common issues
🔄 Update/Reinstall
If you have problems with transformers or torchvision:
```pip uninstall transformers torchvision```

```pip install transformers torchvision```

## ⚙️ ipywidgets/Jupyter
Issues with IProgress:
```pip install ipywidgets```

```jupyter nbextension enable --py widgetsnbextension```

## 🔥 Upgrade PyTorch
Check the latest version and fix torch:
```pip install torch --upgrade```

## 📚 Install missing libraries
If there is an error indicating that a library is missing, install it with the command:
```pip install <library_name>```

## How to Run DOCKER
```docker run -d -p 5000:5000 -e OPENAI_API_KEY="your-openai-api-key-here" chatbot_ai_platform```

## Install PythaiNLP model with English model
```python -m spacy download en_core_web_sm```

## 🙋‍♂️ Contact
If you find any problems or suggestions, please open an Issue or pull request
