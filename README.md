## ğŸ§  Using Long-Term Memory (LTM) in this project
This project supports Long-Term Memory (LTM) to enable AI to â€œrememberâ€ or â€œreferenceâ€ past conversations/data accurately (e.g. previous conversations, data in databases, documents embedded in Vector Store, etc.), which allows the system to respond intelligently and consistently.

## ğŸ’¡ What is LTM?
Long-Term Memory here means storing important data for a long time (e.g. conversations, text, references, embeddings) in a database such as MongoDB or Pinecone to be reused and linking previous knowledge to what the AI â€‹â€‹is interacting with.

## ğŸ› ï¸ How to use LTM in this project
1. Prepare the environment
You must set the correct Environment Variables (MONGO_URL, PINECONE_API_KEY, etc.)

See the settings details in the "Getting Started" topic above.

2. How it works
When AI receives new input (e.g. questions from users)
â†’ The system will pull the relevant context from LTM (MongoDB/Pinecone)
â†’ The AI â€‹â€‹analyzes that context and responds in a way that is consistent with what the user has said or asked.

3. Sample workflow
Embedding

When uploading files/conversations Data is generated by an Embedding and stored in a Vector Store (e.g. Pinecone).

Pull context

When a user asks a question, the system uses the question's Embedding to search for the closest context from the Vector Store or database.

Answers by referencing prior knowledge

The AI â€‹â€‹combines the found context with the prompt to generate an answer.

4. Related important code files
embed_MongoDB.py / retrival_MongoDB.py
For handling Embedding and Retrieval from MongoDB

embed_pinecone.py / retrival_Pinecone.py
For Embedding and Retrieval from Pinecone

Prompt.py
Format the prompt/context to be sent to LLM

## ğŸ Python Version
Python: 3.13.x

## ğŸš€ Getting Started
ğŸ› ï¸ 1. Create an Environment
```python -m venv venv```

ğŸ“¦ 2. Install the Library via the environment
```pip install -r requirements.txt```

ğŸ” 3. Set the Environment Variables
Create a .env file inside the venv/ folder Then add the values:

<pre>OPENAI_API_KEY=your_openai_api_key
MONGO_URL=your_localhost_or_remote_url
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENV=your_pinecone_environment
EMBEDDING=embedding_model_name_from_openai
FACEBOOK_ACCESS_TOKEN=TOKEN_API_FACEBOOK
HF_TOKEN=your_huggingface_token
TYPHOON_API_KEY=your_key
TYPHOON_API_URL=https://api.opentyphoon.ai/v1
</pre>

You can get the typhoon api key from https://playground.opentyphoon.ai/api-key

## ğŸ§ª How to run the project
â–¶ï¸ Run the Backend (FastAPI)
```cd main_backend```

```uvicorn main:app --reload --port 8000```

## Alternative run frontend 

## ğŸ–¼ï¸ Run Frontend (Streamlit)
Open a new Terminal:
```cd frontend```

```streamlit run app.py```
## ğŸ–¼ï¸ Run Frontend (Prototype)
```cd frontend```

```npm run dev```

## ğŸ› ï¸ Fix common issues
ğŸ”„ Update/Reinstall
If you have problems with transformers or torchvision:
```pip uninstall transformers torchvision```

```pip install transformers torchvision```

## âš™ï¸ ipywidgets/Jupyter
Issues with IProgress:
```pip install ipywidgets```

```jupyter nbextension enable --py widgetsnbextension```

## ğŸ”¥ Upgrade PyTorch
Check the latest version and fix torch:
```pip install torch --upgrade```

## ğŸ“š Install missing libraries
If there is an error indicating that a library is missing, install it with the command:
```pip install <library_name>```

## How to Run DOCKER
```docker run -d -p 5000:5000 -e OPENAI_API_KEY="your-openai-api-key-here" chatbot_ai_platform```

## Install PythaiNLP model with English model
```python -m spacy download en_core_web_sm```

## ğŸ™‹â€â™‚ï¸ Contact
If you find any problems or suggestions, please open an Issue or pull request
