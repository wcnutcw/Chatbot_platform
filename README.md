## ğŸ§© Architecture
![CHEESE!](Screenshot 2025-10-08 113040.png)


## ğŸ§  Long-Term Memory (LTM) Usage in This Project
This project supports Long-Term Memory (LTM), enabling the AI to â€œrememberâ€ and reference previous conversations or data (e.g., past chats, database entries, or vectorized documents).
This allows the system to deliver more intelligent, context-aware, and continuous responses.

## ğŸ’¡ What Is LTM?
Long-Term Memory refers to storing important data for long-term use â€” such as chat histories, text content, references, or embeddings â€” in databases like MongoDB or Pinecone.
This makes it possible to retrieve and use old information when generating new responses.

## ğŸ› ï¸ à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ LTM à¹ƒà¸™à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸™à¸µà¹‰
1. Environment Setup
You must configure environment variables correctly (MONGO_URL, PINECONE_API_KEY, etc.).
See the â€œGetting Startedâ€ section below for more details.

2. Core Workflow
When the AI receives a new input (e.g., a user question):

â†’Retrieve context â€“ The system fetches relevant information from LTM (MongoDB or Pinecone).

â†’Analyze â€“ The AI uses the retrieved context to understand the current query in relation to past interactions.

â†’Respond â€“ It generates an answer thatâ€™s consistent with previous information or conversations.

3. Example Workflow
Embedding Data

When you upload a file or conversation, the content is embedded and stored in a Vector Store (e.g., Pinecone).

Retrieve Context

When a user asks a question, the system embeds the query and searches for the most similar contexts from the Vector Store or database.

Generate Response

The AI combines the retrieved context with a structured prompt to generate a final answer.

4. à¹„à¸Ÿà¸¥à¹Œà¹‚à¸„à¹‰à¸”à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡
embed_MongoDB.py / retrival_MongoDB.py
Manage embedding and retrieval from MongoDB

embed_pinecone.py / retrival_Pinecone.py
Handle embedding and retrieval using Pinecone

Prompt.py
Formats prompts and integrates contextual data for LLM input

## ğŸ Python Version
Python: 3.13.x

## ğŸš€ Getting Started
ğŸ› ï¸ 1. Create Environment
```python -m venv venv```

ğŸ“¦ 2. Install Dependencies
```pip install -r requirements.txt```


ğŸ” 3. Set Environment Variables
Create a .env file inside the venv/ directory and add:

<pre>OPENAI_API_KEY=your_openai_api_key
MONGO_URL=your_localhost_or_remote_url
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENV=your_pinecone_environment
EMBEDDING=embedding_model_name_from_openai
FACEBOOK_ACCESS_TOKEN = TOKEN_API_FACEBOOK
HF_TOKEN=your_huggingface_token
TYPHOON_API_KEY=your_key
TYPHOON_API_URL=https://api.opentyphoon.ai/v1
</pre>

You can get your Typhoon API key from https://playground.opentyphoon.ai/api-key

## ğŸ“„ Required File: data.json (in main_backend/)
Example:
<pre>
[
  {
    "question": "à¹€à¸¡à¸¥à¸™à¸´à¸ªà¸´à¸•à¸‚à¸­à¸‡à¸«à¸™à¸¹à¸¡à¸µà¸›à¸±à¸à¸«à¸²à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸‚à¹‰à¸²à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸„à¹ˆà¸°",
    "answer": "à¸à¸£à¸“à¸µà¸£à¸«à¸±à¸ªà¸œà¹ˆà¸²à¸™à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¸«à¸£à¸·à¸­à¸–à¸¹à¸à¸£à¸°à¸‡à¸±à¸šà¸šà¸±à¸à¸Šà¸µ à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸‚à¹‰à¸²à¹„à¸›à¹à¸à¹‰à¹„à¸”à¹‰à¸•à¸²à¸¡ Link à¸™à¸µà¹‰ ***"
  },
  {
    "question": "à¸­à¸¢à¸²à¸à¸—à¸£à¸²à¸šà¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸ªà¸¡à¸±à¸„à¸£à¹€à¸‚à¹‰à¸²à¹€à¸£à¸µà¸¢à¸™à¸•à¹ˆà¸­à¸¡à¸«à¸²à¸§à¸´à¸—à¸¢à¸²à¸¥à¸±à¸¢à¸„à¹ˆà¸°",
    "answer": "à¸ªà¸²à¸¡à¸²à¸£à¸–à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸à¸²à¸£à¸ªà¸¡à¸±à¸„à¸£à¹„à¸”à¹‰à¸—à¸µà¹ˆ Link à¸™à¸µà¹‰ "
  }]
</pre>

## ğŸ§ª Running the Project
â–¶ï¸ Run Backend (FastAPI)
```cd main_backend```

```uvicorn main:app --host 0.0.0.0 --port 8000 --reload```

## ğŸ–¼ï¸ Run Frontend (Streamlit) That is Optional for Test
Open a new terminal:
```cd frontend```

```streamlit run app.py```

## ğŸ–¼ï¸ ğŸ§© Run Frontend Prototype (Prototype)
```cd frontend```

```npm run dev```

## ğŸ› ï¸ Common Issues & Fixes
ğŸ”„ Update or Reinstall Packages
If you face issues with transformers or torchvision:
```pip uninstall transformers torchvision```

```pip install transformers torchvision```

## âš™ï¸ Fix IProgress / Jupyter Issues
```pip install ipywidgets```

```jupyter nbextension enable --py widgetsnbextension```

## ğŸ”¥ Upgrade PyTorch
à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¹à¸¥à¸°à¹à¸à¹‰à¹„à¸‚à¸‚à¸­à¸‡ torch:
```pip install torch --upgrade```

##  ğŸ“š Missing Libraries
If an error indicates a missing library:
```pip install <library_name>```

## ğŸ³ Run with Docker
```docker run -d -p 5000:5000 -e OPENAI_API_KEY="your-openai-api-key-here" chatbot_ai_platform```

## Don't forget ! ğŸ§  Install NLP Models (for English)
```python -m spacy download en_core_web_sm```

## ğŸ™‹â€â™‚ï¸ Contact
If you encounter bugs or have suggestions, please open an Issue or submit a Pull Request.

