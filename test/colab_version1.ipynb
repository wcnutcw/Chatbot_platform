{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f242d13c",
   "metadata": {},
   "source": [
    "Description\n",
    "\n",
    "Embedding Model : text-embedding-3-small\n",
    "\n",
    "Vector DB : Pinecone\n",
    "\n",
    "โดยการทดสอบมีวิธีการที่แตกต่างกัน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99a8816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import AsyncOpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from docx import Document\n",
    "import fitz\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c3876ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY\n",
    "PINECONE_API_KEY : str\n",
    "PINECONE_ENV : str\n",
    "OPENAI_API_KEY : str \n",
    "EMBEDDING : str \n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY, environment= PINECONE_ENV)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBEDDING = os.getenv(\"EMBEDDING\")\n",
    "client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8d6de726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upload เสร็จ 250 records ในเวลา 0.00 วินาที\n",
      "✅ Shape after cleansing: (250, 11)\n"
     ]
    }
   ],
   "source": [
    "# Upload file\n",
    "start_upload = time.perf_counter()\n",
    "file_path = \"../data\"\n",
    "dfs = []\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "for filename in os.listdir(file_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(file_path, filename))\n",
    "        dfs.append(df)\n",
    "    if filename.endswith('.xlsx'):\n",
    "        df = pd.read_excel(os.path.join(file_path, filename))\n",
    "        for sheet_name in df.sheet_names:\n",
    "            sheet_df = df.parse(sheet_name)\n",
    "        dfs.append(df)\n",
    "    if  filename.endswith(\".docx\"):\n",
    "        text = read_docx(os.path.join(file_path, filename))\n",
    "        df = pd.DataFrame({\"text\": [text]})\n",
    "        dfs.append(df)\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        text = read_pdf(os.path.join(file_path, filename))\n",
    "        df = pd.DataFrame({\"text\": [text]})\n",
    "        dfs.append(df)\n",
    "        print(dfs)\n",
    "\n",
    "if filename.endswith((\".csv\", \".xlsx\")):\n",
    "  df_combined = pd.concat(dfs, ignore_index=True)\n",
    "  df_combined.dropna(inplace=True)\n",
    "  df_combined.drop_duplicates(inplace=True)\n",
    "  df_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "elif filename.endswith((\".pdf\", \".docx\")):\n",
    "  df_combined = pd.DataFrame({\"text\": dfs})\n",
    "\n",
    "end_upload= time.perf_counter()\n",
    "upload_time = end_upload - start_upload\n",
    "print(f\"✅ Upload เสร็จ {len(df_combined)} records ในเวลา {upload_time:.2f} วินาที\")\n",
    "\n",
    "print(\"✅ Shape after cleansing:\", df_combined.shape)\n",
    "# df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b32199",
   "metadata": {},
   "source": [
    "Pattern 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3431e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จทั้งหมด 250 records ในเวลา 3.84 วินาที\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def embed_batch(batch, embed):\n",
    "    response = await client.embeddings.create(model=embed, input=batch)\n",
    "    if hasattr(response, \"data\") and response.data:\n",
    "        return [item.embedding for item in response.data]\n",
    "    else:\n",
    "        raise ValueError(\"No 'data' found or 'data' is empty.\")\n",
    "\n",
    "async def batch_process_embedding_async(text_list, embed, batch_size=100):\n",
    "    tasks = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        tasks.append(embed_batch(batch,embed))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    embeddings = [embedding for batch in results for embedding in batch]\n",
    "    return embeddings\n",
    "\n",
    "start_embed_2 = time.perf_counter()\n",
    "texts = []\n",
    "metadata_list = []\n",
    "for i, row in df_combined.iterrows():\n",
    "    metadata = row.to_dict()\n",
    "    text = \"\\n\".join([f\"{k}: {v}\" for k, v in metadata.items()])  # ใช้ key: value\n",
    "    texts.append(text)\n",
    "    metadata_list.append((f\"vec-{i}\", metadata))\n",
    "\n",
    "\n",
    "embeddings = await batch_process_embedding_async(texts,EMBEDDING)\n",
    "\n",
    "end_embed_2 = time.perf_counter()\n",
    "embed_time_2 = end_embed_2 -start_embed_2\n",
    "print(f\"✅ Embedding เสร็จทั้งหมด {len(embeddings)} records ในเวลา {embed_time_2:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd1767d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "async def embed_batch(batch, embed):\n",
    "    response = await client.embeddings.create(model=embed, input=batch)\n",
    "    if hasattr(response, \"data\") and response.data:\n",
    "        return [item.embedding for item in response.data]\n",
    "    else:\n",
    "        raise ValueError(\"No 'data' found or 'data' is empty.\")\n",
    "\n",
    "async def batch_process_embedding_async(text_list, embed, batch_size=100):\n",
    "    tasks = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        tasks.append(embed_batch(batch,embed))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    embeddings = [embedding for batch in results for embedding in batch]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bca1b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จทั้งหมด 250 records ในเวลา 2.84 วินาที\n"
     ]
    }
   ],
   "source": [
    "# Prepare vectors for upsert\n",
    "start_embed_2 = time.perf_counter()\n",
    "texts = []\n",
    "metadata_list = []\n",
    "for i, row in df_combined.iterrows():\n",
    "    metadata = row.to_dict()\n",
    "    text = \"\\n\".join([f\"{k}: {v}\" for k, v in metadata.items()])  # ใช้ key: value\n",
    "    texts.append(text)\n",
    "    metadata_list.append((f\"vec-{i}\", metadata))\n",
    "\n",
    "\n",
    "embeddings = await batch_process_embedding_async(texts,EMBEDDING)\n",
    "\n",
    "end_embed_2 = time.perf_counter()\n",
    "embed_time_2 = end_embed_2 -start_embed_2\n",
    "print(f\"✅ Embedding เสร็จทั้งหมด {len(embeddings)} records ในเวลา {embed_time_2:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fceac52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def upsert_batch(index, vectors_batch, namespace):\n",
    "    try:\n",
    "        index.upsert(vectors=vectors_batch, namespace=namespace)\n",
    "    except Exception as e:\n",
    "        print(\"❌ Upsert error:\", e)\n",
    "\n",
    "async def parallel_upsert(index, vectors, namespace, batch_size=100, concurrency_limit=5):\n",
    "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
    "    async def limited_upsert(batch):\n",
    "        async with semaphore:\n",
    "            await upsert_batch(index, batch, namespace)\n",
    "    tasks = [\n",
    "        limited_upsert(vectors[i:i + batch_size])\n",
    "        for i in range(0, len(vectors), batch_size)\n",
    "    ]\n",
    "    await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6146393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes: ['test-1', 'd', 'test-2', 'default-index', 'test12']\n",
      "Index 'test-1' exists. Deleting it...\n",
      "Index 'test-1' deleted successfully.\n",
      "Index 'test-1' has been created successfully.\n",
      "✅ Upsert Pinecone เสร็จ 250 vectors ในเวลา 22.98 วินาที\n"
     ]
    }
   ],
   "source": [
    "index_name = \"test-1\"\n",
    "namespace = \"test-1\"\n",
    "\n",
    "start_upsert_2 = time.perf_counter()\n",
    "vectors = []\n",
    "for (vec_id, metadata), embedding, raw_text in zip(metadata_list, embeddings, texts):\n",
    "    vectors.append({\n",
    "        \"id\": vec_id,\n",
    "        \"values\": embedding,\n",
    "        \"metadata\": {\n",
    "            **metadata,\n",
    "            \"raw_text\": raw_text  # ฝัง raw_text ไว้ใน metadata\n",
    "        }\n",
    "    })\n",
    "index_list = pc.list_indexes().names()\n",
    "print(f\"Existing indexes: {index_list}\")\n",
    "\n",
    "if index_name in index_list:\n",
    "        print(f\"Index '{index_name}' exists. Deleting it...\")\n",
    "        pc.delete_index(index_name)\n",
    "        print(f\"Index '{index_name}' deleted successfully.\")\n",
    "\n",
    "\n",
    "spec = ServerlessSpec(cloud=\"aws\", region=PINECONE_ENV)\n",
    "pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=1536,  # vector size\n",
    "                metric=\"cosine\",\n",
    "                spec=spec\n",
    "                )\n",
    "print(f\"Index '{index_name}' has been created successfully.\")\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "await parallel_upsert(index, vectors, namespace, batch_size=100)\n",
    "\n",
    "end_upsert_2 = time.perf_counter()\n",
    "upsert_time_2 = end_upsert_2  - start_upsert_2\n",
    "print(f\"✅ Upsert Pinecone เสร็จ {len(vectors)} vectors ในเวลา {upsert_time_2 :.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d1bc6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "async def retrieve_context_from_pinecone(question: str, index_name: str, namespace: str, top_k: int = 55):\n",
    "    embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "    question_vector = embedder.embed_query(question)\n",
    "    index = pc.Index(index_name)\n",
    "    result = index.query(vector=question_vector, top_k=top_k, include_metadata=True, namespace=namespace)\n",
    "    context_chunks = []\n",
    "    for match in result[\"matches\"]:\n",
    "        raw_text = match[\"metadata\"].get(\"raw_text\", str(match[\"metadata\"]))\n",
    "        context_chunks.append(raw_text)\n",
    "    return \"\\n\".join(context_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "46315c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวน token ทั้งหมดใน context: 4851\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(text, model=\"text-embedding-3-small\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "question = \"สินค้ามีอะไรบ้าง และมีจำนวนเท่าไร\"\n",
    "context = await retrieve_context_from_pinecone(question, index_name, namespace)\n",
    "num_tokens = count_tokens(context)\n",
    "print(f\"จำนวน token ทั้งหมดใน context: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208def6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คำตอบ: จากการวิเคราะห์ข้อมูล พบว่ามีสินค้าทั้งหมด 6 ประเภท ดังนี้:\n",
      "\n",
      "1. ยีนส์ (Jeans) จำนวน 8 ตัว\n",
      "2. ตู้เย็น (Refrigerator) จำนวน 9 เครื่อง\n",
      "3. สมาร์ทโฟน (Smartphone) จำนวน 14 เครื่อง\n",
      "4. นาฬิกาอัจฉริยะ (Smartwatch) จำนวน 16 เรือน\n",
      "5. เครื่องซักผ้า (Washing Machine) จำนวน 14 เครื่อง\n",
      "6. เสื้อยืด (T-Shirt) จำนวน 16 ตัว\n",
      "\n",
      "นอกจากนี้ยังมีสินค้าประเภทอื่นๆ อีก 3 ประเภท ได้แก่ รองเท้าวิ่ง (Running Shoes) จำนวน 7 คู่, หูฟัง (Headphones) จำนวน 2 คู่ และ แล็ปท็อป (Laptop) จำนวน 16 เครื่อง\n",
      "\n",
      "ดังนั้น สรุปได้ว่ามีสินค้าทั้งหมด 9 ประเภท และจำนวนรวมทั้งหมดคือ 92 รายการ\n",
      "⏱ ใช้เวลาในการตอบ: 18.32 วินาที\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "start_q_2 = time.perf_counter()\n",
    "index_name = \"test-2\"\n",
    "namespace = \"test-2\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "ข้อมูลต่อไปนี้มาจากไฟล์ในรูปแบบตาราง เช่น CSV หรือ Excel ซึ่งอาจมีหลายประเภทข้อมูลและหลายแถว:\n",
    "{context}\n",
    "\n",
    "คำถามของฉันคือ: \"{question}\"\n",
    "\n",
    "กรุณาตอบโดย:\n",
    "- วิเคราะห์ข้อมูลทั้งหมดให้ครบถ้วน\n",
    "- สรุปคำตอบโดยใช้ภาษาธรรมดา ชัดเจน และไม่ใช้การจัดรูปแบบตัวหนา หัวข้อ หรือสัญลักษณ์พิเศษ เช่น ** หรือ -\n",
    "- หากมีหลายรายการสินค้า ให้ระบุชื่อสินค้า พร้อมจำนวน และหน่วยตามลักษณะของสินค้า เช่น เครื่อง, ตัว, คู่, เล่ม ฯลฯ\n",
    "- หากต้องรวมจำนวน ให้รวมและแสดงยอดรวมทั้งหมด\n",
    "- ตอบเป็นภาษาไทยแบบเป็นธรรมชาติ เข้าใจง่าย เหมือนอธิบายให้คนทั่วไปฟัง\n",
    "- หากไม่พบข้อมูลที่เกี่ยวข้อง ให้ตอบว่า \"ไม่พบข้อมูลที่เกี่ยวข้อง\"\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\",api_key=OPENAI_API_KEY)\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "\n",
    "end_q_2 = time.perf_counter()\n",
    "response_time_2 = end_q_2 - start_q_2\n",
    "\n",
    "print(\"คำตอบ:\", response.content)\n",
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time_2:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c486874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จทั้งหมด 250 records ในเวลา 2.84 วินาที\n",
      "✅ Upsert Pinecone เสร็จ 250 vectors ในเวลา 22.98 วินาที\n",
      "⏱ ใช้เวลาในการตอบ: 18.32 วินาที\n",
      "เวลาโดยรวมupload pineconeทั้งหมด : 25.82 \n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Embedding เสร็จทั้งหมด {len(embeddings)} records ในเวลา {embed_time_2:.2f} วินาที\")\n",
    "print(f\"✅ Upsert Pinecone เสร็จ {len(vectors)} vectors ในเวลา {upsert_time_2:.2f} วินาที\")\n",
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time_2:.2f} วินาที\")\n",
    "print(f\"เวลาโดยรวมupload pineconeทั้งหมด : {embed_time_2+upsert_time_2:.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c35aca3",
   "metadata": {},
   "source": [
    "Pattern 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cda0012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จทั้งหมด 250 records ในเวลา 6.85 วินาที\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "async def embed_batch(batch, embed):\n",
    "    response = await client.embeddings.create(model=embed, input=batch)\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "async def embed_all_rows(df,embed ,batch_size=100):\n",
    "    texts = [\" \".join(map(str, row.values)) for _, row in df.iterrows()]\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        embeddings = await embed_batch(batch,embed)\n",
    "        all_embeddings.extend(embeddings)\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "start_embed_time = time.perf_counter()\n",
    "embeddings = asyncio.run(embed_all_rows(df_combined,EMBEDDING))\n",
    "end_embed_time = time.perf_counter()\n",
    "embed_time = end_embed_time  - start_embed_time\n",
    "\n",
    "print(f\"✅ Embedding เสร็จทั้งหมด {len(embeddings)} records ในเวลา {embed_time:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83083ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upsert Pinecone เสร็จ 250 vectors ในเวลา 24.52 วินาที\n"
     ]
    }
   ],
   "source": [
    "start_upsert = time.perf_counter()\n",
    "# ลบ index เดิมถ้ามี\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "spec = ServerlessSpec(cloud=\"aws\", region=PINECONE_ENV)\n",
    "# pc.create_index(name=index_name, dimension=1536, metric=\"cosine\", spec=spec)\n",
    "pc.create_index(index_name, dimension=len(embeddings[0]), metric=\"cosine\", spec=spec)\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# สร้าง vectors\n",
    "vectors = [{\n",
    "    \"id\": f\"vec-{i}\",\n",
    "    \"values\": embeddings[i],\n",
    "    \"metadata\": df_combined.iloc[i].to_dict()\n",
    "} for i in range(len(embeddings))]\n",
    "\n",
    "# ⏱ จับเวลา upsert\n",
    "index.upsert(vectors=vectors, namespace=namespace)\n",
    "end_upsert = time.perf_counter()\n",
    "upsert_time =  end_upsert - start_upsert\n",
    "\n",
    "print(f\"✅ Upsert Pinecone เสร็จ {len(vectors)} vectors ในเวลา {upsert_time :.2f} วินาที\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b2491601",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieve_context_from_pinecone(question: str, index_name: str, namespace: str, top_k: int = 50):\n",
    "    embedder = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    question_vector = embedder.embed_query(question)\n",
    "\n",
    "    index = pc.Index(index_name)\n",
    "    result = index.query(\n",
    "        vector=question_vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace\n",
    "    )\n",
    "\n",
    "    context_chunks = []\n",
    "    for match in result['matches']:\n",
    "        metadata = match['metadata']\n",
    "        context_chunks.append(str(metadata))\n",
    "\n",
    "    return \"\\n\".join(context_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9ac1af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวน token ทั้งหมดใน context: 4401\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(text, model=\"text-embedding-3-small\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "question = \"สินค้ามีอะไรบ้าง และมีจำนวนเท่าไร\"\n",
    "context = await retrieve_context_from_pinecone(question, index_name, namespace)\n",
    "num_tokens_p2 = count_tokens(context)\n",
    "print(f\"จำนวน token ทั้งหมดใน context: {num_tokens_p2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4dba6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คำตอบ: จากข้อมูลที่ได้รับ พบว่ามีสินค้าหลายประเภทที่ถูกจำหน่าย โดยมีรายละเอียดดังนี้:\n",
      "\n",
      "1. แล็ปท็อป (Laptop) จำนวน 26 เครื่อง\n",
      "2. รองเท้าวิ่ง (Running Shoes) จำนวน 24 คู่\n",
      "3. หนังสือ (Book) จำนวน 20 เล่ม\n",
      "4. หูฟัง (Headphones) จำนวน 23 คู่\n",
      "5. เสื้อยืด (T-Shirt) จำนวน 12 ตัว\n",
      "6. สมาร์ทวอทช์ (Smartwatch) จำนวน 20 เรือน\n",
      "7. สมาร์ทโฟน (Smartphone) จำนวน 18 เครื่อง\n",
      "8. ตู้เย็น (Refrigerator) จำนวน 4 เครื่อง\n",
      "\n",
      "รวมทั้งหมดมีสินค้า 147 รายการ จากหลายหมวดหมู่ที่ถูกจำหน่ายในข้อมูลที่ได้รับ.\n",
      "⏱ ใช้เวลาในการตอบ: 14.70 วินาที\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "start_q = time.perf_counter()\n",
    "\n",
    "question = \"สินค้ามีอะไรบ้าง และมีจำนวนเท่าไร\"\n",
    "context = await retrieve_context_from_pinecone(question, index_name, namespace)\n",
    "prompt = f\"\"\"\n",
    "ข้อมูลต่อไปนี้มาจากไฟล์ในรูปแบบตาราง เช่น CSV หรือ Excel ซึ่งอาจมีหลายประเภทข้อมูลและหลายแถว:\n",
    "{context}\n",
    "\n",
    "คำถามของฉันคือ: \"{question}\"\n",
    "\n",
    "กรุณาตอบโดย:\n",
    "- วิเคราะห์ข้อมูลทั้งหมดให้ครบถ้วน\n",
    "- สรุปคำตอบโดยใช้ภาษาธรรมดา ชัดเจน และไม่ใช้การจัดรูปแบบตัวหนา หัวข้อ หรือสัญลักษณ์พิเศษ เช่น ** หรือ -\n",
    "- หากมีหลายรายการสินค้า ให้ระบุชื่อสินค้า พร้อมจำนวน และหน่วยตามลักษณะของสินค้า เช่น เครื่อง, ตัว, คู่, เล่ม ฯลฯ\n",
    "- หากต้องรวมจำนวน ให้รวมและแสดงยอดรวมทั้งหมด\n",
    "- ตอบเป็นภาษาไทยแบบเป็นธรรมชาติ เข้าใจง่าย เหมือนอธิบายให้คนทั่วไปฟัง\n",
    "- หากไม่พบข้อมูลที่เกี่ยวข้อง ให้ตอบว่า \"ไม่พบข้อมูลที่เกี่ยวข้อง\"\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4-turbo\",api_key=OPENAI_API_KEY)\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "\n",
    "end_q = time.perf_counter()\n",
    "response_time = end_q - start_q\n",
    "\n",
    "print(\"คำตอบ:\", response.content)\n",
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66a8239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จทั้งหมด 250 records ในเวลา 6.85 วินาที\n",
      "✅ Upsert Pinecone เสร็จ 250 vectors ในเวลา 24.52 วินาที\n",
      "⏱ ใช้เวลาในการตอบ: 14.70 วินาที\n",
      "เวลาโดยรวมupload pineconeทั้งหมด : 31.37 \n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Embedding เสร็จทั้งหมด {len(embeddings)} records ในเวลา {embed_time:.2f} วินาที\")\n",
    "print(f\"✅ Upsert Pinecone เสร็จ {len(vectors)} vectors ในเวลา {upsert_time :.2f} วินาที\")\n",
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time:.2f} วินาที\")\n",
    "print(f\"เวลาโดยรวมupload pineconeทั้งหมด : {embed_time+upsert_time:.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af65a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
