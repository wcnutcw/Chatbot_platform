{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd3346b",
   "metadata": {},
   "source": [
    "Description\n",
    "\n",
    "Embedding Model : text-embedding-3-small , sentence-transformers/LaBSE\n",
    "\n",
    "Vector DB : MongoDB\n",
    "\n",
    "โดยการทดสอบมีวิธีการที่แตกต่างกันสำหรับการทำ RAG และ การทำ Tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7198383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\user\\OneDrive\\Desktop\\Test_BOT_CSV\\test\n",
      "Env Path: c:\\Users\\user\\OneDrive\\Desktop\\Test_BOT_CSV\\venv\\.env\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from openai import AsyncOpenAI\n",
    "from pymongo import MongoClient\n",
    "from docx import Document\n",
    "import tiktoken\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from PyPDF2 import PdfReader\n",
    "from sklearn.decomposition import PCA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)  # พิมพ์ที่อยู่ปัจจุบัน\n",
    "\n",
    "# ปรับเส้นทางไปยังไฟล์ .env ในโฟลเดอร์ venv\n",
    "env_path = Path(current_directory).parent / 'venv' / '.env'\n",
    "print(\"Env Path:\", env_path)  # พิมพ์เส้นทางที่ไปยัง .env\n",
    "\n",
    "load_dotenv(dotenv_path=env_path,override=True)\n",
    "\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3222c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEY \n",
    "OPENAI_API_KEY : str \n",
    "EMBEDDING : str \n",
    "MONGO_URI : str\n",
    "\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBEDDING = os.getenv(\"EMBEDDING\")\n",
    "client_openai = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "mongo_client = MongoClient(MONGO_URI)\n",
    "db = mongo_client[\"vector_db\"]\n",
    "collection = db[\"vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4116b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"./data_csv_xlsx\"\n",
    "file_path = \"./data_pdf\"\n",
    "# file_path = \"./data_docx\"\n",
    "# 3. Define helper functions\n",
    "def read_docx(path):\n",
    "    doc = Document(path)\n",
    "    text = []\n",
    "    for para in doc.paragraphs:\n",
    "        text.append(para.text.strip())  # เก็บข้อความทุกย่อหน้าลงใน list\n",
    "    return text\n",
    "\n",
    "def read_pdf(path):\n",
    "    reader = PdfReader(path)\n",
    "    pages = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            pages.append(text.strip())\n",
    "    return pages\n",
    "\n",
    "\n",
    "\n",
    "# Embedding By HuggingFace\n",
    "# โหลดโมเดลและ tokenizer\n",
    "# model_name = \"bert-base-multilingual-cased\"\n",
    "# local_dir = \"./models/bert-multi\"  # ที่เก็บโมเดลแบบ local\n",
    "\n",
    "# # # ดาวน์โหลด tokenizer และ model แล้วบันทึกไว้\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# tokenizer.save_pretrained(local_dir)\n",
    "# model.save_pretrained(local_dir)\n",
    "\n",
    "# # ใช้ GPU ถ้ามี\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# def embed_batch_bert(batch_texts):\n",
    "#     encoded_input = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "#     encoded_input = {key: val.to(device) for key, val in encoded_input.items()}\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         output = model(**encoded_input)\n",
    "    \n",
    "#     # ใช้ CLS token เป็น embedding (สามารถเปลี่ยนเป็น mean pooling ได้)\n",
    "#     embeddings = output.last_hidden_state[:, 0, :]  # CLS token\n",
    "#     return embeddings.cpu().numpy()\n",
    "\n",
    "# async def batch_process_embedding_async(text_list, batch_size=32):\n",
    "#     loop = asyncio.get_event_loop()\n",
    "#     embeddings = []\n",
    "\n",
    "#     for i in range(0, len(text_list), batch_size):\n",
    "#         batch = text_list[i:i + batch_size]\n",
    "#         # run embed_batch_bert in executor to simulate async\n",
    "#         batch_embeddings = await loop.run_in_executor(None, embed_batch_bert, batch)\n",
    "#         embeddings.extend(batch_embeddings)\n",
    "#     return embeddings \n",
    "\n",
    "#GPT\n",
    "async def embed_batch(batch, embed_model):\n",
    "    response = await client_openai.embeddings.create(model=embed_model, input=batch)\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "async def batch_process_embedding_async(text_list, embed_model, batch_size=100):\n",
    "    tasks = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        tasks.append(embed_batch(batch, embed_model))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    embeddings = [embedding for batch in results for embedding in batch]\n",
    "    return embeddings\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def count_tokens(text, model):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# ฟังก์ชันนับจำนวนโทเค็น\n",
    "def count_tokens_2(text, model):\n",
    "    # โหลด tokenizer สำหรับโมเดลที่กำหนด\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    # ใช้ tokenizer ในการแปลงข้อความเป็นโทเค็นและนับจำนวนโทเค็น\n",
    "    encoded = tokenizer.encode(text, truncation=True, padding=False)\n",
    "    return len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23227a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upload เสร็จ 149 records ในเวลา 1.89 วินาที\n",
      "✅ Shape after cleansing: (149, 1)\n",
      "0      Fundamentals of Machine Learning \\nand Analyzi...\n",
      "1      Fundamentals of Machine Learning \\nand Analyzi...\n",
      "2      Fundamentals of Machine Learning \\nand Analyzi...\n",
      "3      คคานคา\\nเทคโนโลยธีสารสนเทศสมบัยใหมม่ททาใหด้โลก...\n",
      "4      สารบจัญ\\n บทททท1 Jupyter Notebook ...............\n",
      "                             ...                        \n",
      "144    Fundamentals of Machine Learning and Analyzing...\n",
      "145    138  ความรมตพพตนฐานทางด ตานการเรธยนรมตเครพพองจ...\n",
      "146    Fundamentals of Machine Learning and Analyzing...\n",
      "147    140  ความรมตพพตนฐานทางด ตานการเรธยนรมตเครพพองจ...\n",
      "148    Fundamentals of Machine learning \\nand Analyzi...\n",
      "Name: text, Length: 149, dtype: object\n"
     ]
    }
   ],
   "source": [
    "start_upload = time.perf_counter()\n",
    "dfs = []\n",
    "text_data = []\n",
    "\n",
    "for filename in os.listdir(file_path):\n",
    "    full_path = os.path.join(file_path, filename)\n",
    "    \n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(full_path)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    elif filename.endswith('.xlsx'):\n",
    "        excel_data = pd.read_excel(full_path, sheet_name=None)\n",
    "        for sheet in excel_data.values():\n",
    "            dfs.append(sheet)\n",
    "            \n",
    "    elif filename.endswith('.docx'):\n",
    "        text = read_docx(full_path)\n",
    "        text_data.extend(text)\n",
    "        \n",
    "    elif filename.endswith('.pdf'):\n",
    "        texts = read_pdf(full_path)\n",
    "        text_data.extend(texts)\n",
    "\n",
    "# รวมข้อมูลตามประเภท\n",
    "if dfs:\n",
    "    df_combined = pd.concat(dfs, ignore_index=True)\n",
    "    df_combined.dropna(inplace=True)\n",
    "    df_combined.drop_duplicates(inplace=True)\n",
    "    df_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "elif text_data:\n",
    "    df_combined = pd.DataFrame({\"text\": text_data})\n",
    "\n",
    "end_upload = time.perf_counter()\n",
    "print(f\"✅ Upload เสร็จ {len(df_combined)} records ในเวลา {end_upload - start_upload:.2f} วินาที\")\n",
    "print(\"✅ Shape after cleansing:\", df_combined.shape)\n",
    "print(df_combined[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "294c9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "metadata_list = []\n",
    "for i, row in df_combined.iterrows():\n",
    "    metadata = row.to_dict()\n",
    "    text = \"\\n\".join([f\"{k}: {v}\" for k, v in metadata.items()])\n",
    "    texts.append(text)\n",
    "    metadata_list.append((f\"vec-{i}\", metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53dc6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จ 149 records ในเวลา 3.97 วินาที\n"
     ]
    }
   ],
   "source": [
    "start_embed = time.perf_counter()\n",
    "\n",
    "embeddings = await batch_process_embedding_async(texts,EMBEDDING)\n",
    "\n",
    "end_embed = time.perf_counter()\n",
    "embed_time = end_embed - start_embed\n",
    "print(f\"✅ Embedding เสร็จ {len(embeddings)} records ในเวลา {embed_time:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "27a3da0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 149 documents into MongoDB.\n",
      "✅ Upsertเสร็จ 149 records ในเวลา 0.08 วินาที\n"
     ]
    }
   ],
   "source": [
    "start_upsert = time.perf_counter()\n",
    "\n",
    "collection.delete_many({})  \n",
    "documents = []\n",
    "for (vec_id, metadata), embedding, raw_text in zip(metadata_list, embeddings, texts):\n",
    "    documents.append({\n",
    "        \"_id\": vec_id,\n",
    "        \"embedding\": embedding,\n",
    "        \"metadata\": metadata,\n",
    "        \"raw_text\": raw_text\n",
    "    })\n",
    "\n",
    "collection.insert_many(documents)\n",
    "print(f\"✅ Inserted {len(documents)} documents into MongoDB.\")\n",
    "\n",
    "end_upsert = time.perf_counter()\n",
    "upsert_time = end_upsert - start_upsert\n",
    "print(f\"✅ Upsertเสร็จ {len(documents)} records ในเวลา {upsert_time :.2f} วินาที\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4612ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จทั้งหมด 149 records ในเวลา 3.97 วินาที\n",
      "✅ Upsert MongoDB เสร็จ 149 vectors ในเวลา 0.08 วินาที\n",
      "เวลาโดยรวมupload MongoDB ทั้งหมด : 4.04 \n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Embedding เสร็จทั้งหมด {len(embeddings)} records ในเวลา {embed_time:.2f} วินาที\")\n",
    "print(f\"✅ Upsert MongoDB เสร็จ {len(documents)} vectors ในเวลา {upsert_time :.2f} วินาที\")\n",
    "print(f\"เวลาโดยรวมupload MongoDB ทั้งหมด : {embed_time+upsert_time:.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61050f",
   "metadata": {},
   "source": [
    "Pattern 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce27b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieve_context_from_mongodb(question: str, top_k: int = 50):\n",
    "    embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "    question_vector = embedder.embed_query(question)\n",
    "\n",
    "    documents = list(collection.find())\n",
    "    similarities = []\n",
    "    for doc in documents:\n",
    "        score = cosine_similarity(question_vector, doc[\"embedding\"])\n",
    "        similarities.append((score, doc))\n",
    "\n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_docs = [doc[\"raw_text\"] for score, doc in similarities[:top_k]]\n",
    "    return \"\\n\".join(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b3835ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before จำนวน token ถูกตัด ทั้งหมดใน context: 29628\n",
      "After จำนวน token หลังถูกตัด ทั้งหมดใน context: 512\n"
     ]
    }
   ],
   "source": [
    "from tiktoken import encoding_for_model\n",
    "\n",
    "# ใช้สำหรับการทดสอบอ่านไฟล์ \n",
    "def truncate_context(text, max_tokens, model=\"gpt-4\"):\n",
    "    enc = encoding_for_model(model)\n",
    "    tokens = enc.encode(text)\n",
    "    truncated = enc.decode(tokens[:max_tokens])\n",
    "    return truncated\n",
    "\n",
    "question = \"ขอตัวอย่างการเปลี่ยนตำแหน่ง Legend \"\n",
    "context = await retrieve_context_from_mongodb(question)\n",
    "short_context = truncate_context(context, max_tokens=512)\n",
    "num_tokens_bf = count_tokens(context,model=\"text-embedding-3-small\")\n",
    "num_tokens_af = count_tokens(short_context,model=\"text-embedding-3-small\")\n",
    "print(f\"Before จำนวน token ถูกตัด ทั้งหมดใน context: {num_tokens_bf}\")\n",
    "print(f\"After จำนวน token หลังถูกตัด ทั้งหมดใน context: {num_tokens_af}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2562ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จากข้อมูลที่วิเคราะห์ได้ สามารถสรุปเกี่ยวกับการเปลี่ยนตำแหน่ง Legend ใน Matplotlib ได้ดังนี้:  \n",
      "1. การเปลี่ยนตำแหน่ง Legend สามารถทำได้โดยการใช้พารามิเตอร์ 'loc' ในฟังก์ชัน ax.legend()  \n",
      "2. ค่าที่สามารถใส่ใน 'loc' ได้แก่ 'upper left', 'upper right', 'lower left', 'lower right' ซึ่งแทนตำแหน่งที่ต้องการวาง Legend  \n",
      "3. ตัวอย่างการเปลี่ยนตำแหน่ง Legend ไปยัง 'upper left' คือ ax.legend(loc='upper left', frameon=False)  \n",
      "4. ถ้าต้องการเปลี่ยนตำแหน่ง Legend ไปยังตำแหน่งอื่น ๆ สามารถเปลี่ยนค่าใน 'loc' ได้ตามต้องการ\n",
      "\n",
      "สรุป: การเปลี่ยนตำแหน่ง Legend ใน Matplotlib สามารถทำได้ง่ายๆ ผ่านพารามิเตอร์ 'loc' ในฟังก์ชัน ax.legend() ทำให้สามารถปรับตำแหน่งของ Legend ให้เหมาะสมกับกราฟของเราได้."
     ]
    }
   ],
   "source": [
    "# สร้าง PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "ข้อมูลต่อไปนี้ถูกรวบรวมมาจากหลายแหล่งไฟล์ เช่น PDF, Word, Excel หรือ CSV ซึ่งอาจอยู่ในรูปแบบข้อความทั่วไปหรือเป็นข้อมูลเชิงตาราง:\n",
    "{context}\n",
    "\n",
    "คำถามของฉันคือ: \"{question}\"\n",
    "\n",
    "กรุณาตอบโดย:\n",
    "- ไม่ต้องเขียนคำถามซ้ำ\n",
    "- ไม่ต้องขึ้นต้นด้วยคำว่า \"คำตอบ:\"\n",
    "- เริ่มต้นด้วยประโยค เช่น \"จากเอกสารที่อ่าน...\" หรือ \"จากข้อมูลที่วิเคราะห์ได้...\"\n",
    "- จากนั้นจัดคำตอบให้อ่านง่ายในรูปแบบข้อ ๆ\n",
    "- มีสรุปท้ายที่ใช้ถ้อยคำกระชับและไม่ซ้ำกับรายละเอียดด้านบน\n",
    "- หลีกเลี่ยงการตอบซ้ำหรือลอกเนื้อหาเดิมซ้ำหลายรอบ\n",
    "\n",
    "ตัวอย่างที่ 1:\n",
    "จากข้อมูลที่วิเคราะห์ได้ สามารถสรุปเกี่ยวกับ Matplotlib ได้ดังนี้:  \n",
    "1. เป็นไลบรารี่ในภาษา Python สำหรับสร้างภาพกราฟ 2 มิติ และ 3 มิติ  \n",
    "2. รองรับการสร้างกราฟเส้น แท่ง วงกลม ฯลฯ  \n",
    "3. ติดตั้งด้วยคำสั่ง pip install matplotlib  \n",
    "4. เรียกใช้งานผ่าน import matplotlib.pyplot as plt  \n",
    "5. ใช้งานง่ายและมีความยืดหยุ่นสูง\n",
    "\n",
    "สรุป: Matplotlib เป็นเครื่องมือช่วยแสดงข้อมูลเป็นภาพได้อย่างมีประสิทธิภาพ เหมาะกับงานวิเคราะห์ทุกรูปแบบ\n",
    "\n",
    "---\n",
    "\n",
    "กรุณาตอบคำถามต่อไปนี้ในรูปแบบเดียวกัน:\n",
    "\"\"\")\n",
    "\n",
    "# สร้าง Prompt ที่สมบูรณ์\n",
    "final_prompt = prompt_template.format(context=short_context, question=question)\n",
    "\n",
    "# ตั้งค่า LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    streaming=True ,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# ฟังก์ชันประมวลผลแบบ async\n",
    "async def run_async_query(prompt):\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# ประมวลผลและวัดเวลา\n",
    "start_q = time.perf_counter()\n",
    "response = asyncio.run(run_async_query(final_prompt))\n",
    "end_q = time.perf_counter()\n",
    "response_time_1 = end_q - start_q\n",
    "\n",
    "# แสดงผล\n",
    "# print(\"คำตอบ:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af1cd1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱ ใช้เวลาในการตอบ: 17.40 วินาที\n"
     ]
    }
   ],
   "source": [
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time_1:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa7f74",
   "metadata": {},
   "source": [
    "Pattern 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3d5c0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# โหลด tokenizer จาก BERT\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "# โหลดโมเดล LaBSE สำหรับการสร้าง embeddings\n",
    "labse_model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "\n",
    "\n",
    "def reduce_vector_dimension(vec, target_dim):\n",
    "    if vec.ndim == 1:\n",
    "        vec = vec.reshape(1, -1)\n",
    "\n",
    "    current_dim = vec.shape[1]\n",
    "    if current_dim == target_dim:\n",
    "        return vec.flatten()\n",
    "\n",
    "    if vec.shape[0] == 1:\n",
    "        # กรณี sample เดียว ให้เลือกตัดหรือ padding\n",
    "        if current_dim > target_dim:\n",
    "            reduced = vec[:, :target_dim]\n",
    "        else:\n",
    "            pad_width = target_dim - current_dim\n",
    "            reduced = np.pad(vec, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        # มีหลาย sample ใช้ PCA\n",
    "        pca = PCA(n_components=target_dim)\n",
    "        reduced = pca.fit_transform(vec)\n",
    "\n",
    "    return reduced.flatten()\n",
    "\n",
    "\n",
    "\n",
    "# ฟังก์ชัน cosine similarity ที่รองรับเวกเตอร์ 1D\n",
    "def cosine_similarity_2(vec1, vec2):\n",
    "    vec1 = np.array(vec1).flatten()\n",
    "    vec2 = np.array(vec2).flatten()\n",
    "\n",
    "    # ตรวจสอบขนาดของเวกเตอร์\n",
    "    if vec1.shape != vec2.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {vec1.shape} vs {vec2.shape}\")\n",
    "\n",
    "    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
    "        return 0.0  # ป้องกันหารด้วยศูนย์\n",
    "\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "\n",
    "# ฟังก์ชันลดจำนวน token โดยใช้ tokenizer ของ BERT\n",
    "def reduce_token_with_bert(text, max_tokens=512):\n",
    "    encoded = bert_tokenizer(text, truncation=True, max_length=max_tokens, return_tensors='pt')\n",
    "    # แปลง token กลับเป็นข้อความหลังตัด token แล้ว\n",
    "    truncated_text = bert_tokenizer.decode(encoded[\"input_ids\"][0], skip_special_tokens=True)\n",
    "    return truncated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43855efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieve_context_from_mongodb(question: str, top_k: int = 50):\n",
    "    # สร้าง embedding สำหรับคำถามด้วย LaBSE\n",
    "    question_vector = labse_model.encode([question], convert_to_numpy=True)\n",
    "\n",
    "    # ตรวจสอบขนาดของ question_vector\n",
    "    print(f\"Question vector shape: {question_vector.shape}\")\n",
    "\n",
    "    # ดึงข้อมูลจาก MongoDB\n",
    "    documents = list(collection.find())\n",
    "    similarities = []\n",
    "    \n",
    "    # คำนวณ cosine similarity สำหรับแต่ละเอกสาร\n",
    "    for doc in documents:\n",
    "        doc_embedding = np.array(doc[\"embedding\"]).flatten()\n",
    "\n",
    "        # ตรวจสอบขนาดของ doc_embedding\n",
    "        print(f\"Document embedding shape: {doc_embedding.shape}\")\n",
    "\n",
    "        # ปรับขนาดเวกเตอร์ของ doc[\"embedding\"] ให้ตรงกับขนาดของ question_vector\n",
    "        target_dim = question_vector.shape[1]  # ใช้ขนาดของ question_vector\n",
    "        if doc_embedding.shape[0] != target_dim:\n",
    "            doc_embedding = reduce_vector_dimension(doc_embedding, target_dim)\n",
    "\n",
    "        # ตรวจสอบขนาดของ doc_embedding หลังจากลดขนาด\n",
    "        print(f\"Reduced document embedding shape: {doc_embedding.shape}\")\n",
    "\n",
    "        # คำนวณ cosine similarity\n",
    "        score = cosine_similarity_2(question_vector, doc_embedding)\n",
    "        similarities.append((score, doc))\n",
    "\n",
    "    # จัดเรียงตามคะแนน similarity\n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    # คืนค่าข้อความที่ถูกลดจำนวนโทเค็น\n",
    "    reduced_texts = []\n",
    "    for score, doc in similarities[:top_k]:\n",
    "        reduced = reduce_token_with_bert(doc[\"raw_text\"])\n",
    "        reduced_texts.append(reduced)\n",
    "\n",
    "    return \"\\n\".join(reduced_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31a245b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question vector shape: (1, 768)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "Document embedding shape: (1536,)\n",
      "Reduced document embedding shape: (768,)\n",
      "จำนวนโทเค็นใน context: 512\n"
     ]
    }
   ],
   "source": [
    "# question = \"สินค้ามีอะไรบ้าง และมีจำนวนเท่าไร\"\n",
    "question = \"ขอตัวอย่างการเปลี่ยนตำแหน่ง Legend\"\n",
    "context = await retrieve_context_from_mongodb(question)\n",
    "num_tokens_context = count_tokens_2(context, model=\"sentence-transformers/LaBSE\")\n",
    "print(f\"จำนวนโทเค็นใน context: {num_tokens_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5d1edde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวนโทเค็นใน context: 512\n"
     ]
    }
   ],
   "source": [
    "num_tokens_context = count_tokens_2(context, model=\"sentence-transformers/LaBSE\")\n",
    "print(f\"จำนวนโทเค็นใน context: {num_tokens_context}\")\n",
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2742e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "def reduce_context(text, num_tokens_context):\n",
    "    tokens = encoding.encode(text)\n",
    "    tokens = tokens[:num_tokens_context]\n",
    "    return encoding.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0cd9c817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จากข้อมูลที่วิเคราะห์ได้ สามารถสรุปเกี่ยวกับการเปลี่ยนตำแหน่ง Legend ได้ดังนี้:  \n",
      "1. Legend คือ สัญลักษณ์ที่ใช้แสดงความหมายของสี รูปแบบ หรือสัญลักษณ์อื่น ๆ ที่ใช้ในกราฟ\n",
      "2. ใน Matplotlib สามารถเปลี่ยนตำแหน่งของ Legend ได้โดยใช้คำสั่ง plt.legend(loc='ตำแหน่งที่ต้องการ')\n",
      "3. ตำแหน่งที่สามารถกำหนดได้มีดังนี้: 'upper left', 'upper right', 'lower left', 'lower right', 'center left', 'center right', 'lower center', 'upper center', 'center'\n",
      "4. นอกจากนี้ยังสามารถกำหนดตำแหน่งของ Legend ได้โดยใช้พิกัด x และ y ด้วยคำสั่ง plt.legend(bbox_to_anchor=(x, y))\n",
      "\n",
      "สรุป: การเปลี่ยนตำแหน่งของ Legend ใน Matplotlib สามารถทำได้ง่ายๆ ผ่านคำสั่ง plt.legend() ที่มีอาร์กิวเมนต์สำหรับกำหนดตำแหน่งที่ต้องการ"
     ]
    }
   ],
   "source": [
    "# ตัด context\n",
    "context_trimmed = reduce_context(context, num_tokens_context)\n",
    "\n",
    "# สร้าง PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "ข้อมูลต่อไปนี้ถูกรวบรวมมาจากหลายแหล่งไฟล์ เช่น PDF, Word, Excel หรือ CSV ซึ่งอาจอยู่ในรูปแบบข้อความทั่วไปหรือเป็นข้อมูลเชิงตาราง:\n",
    "{context}\n",
    "\n",
    "คำถามของฉันคือ: \"{question}\"\n",
    "\n",
    "กรุณาตอบโดย:\n",
    "- ไม่ต้องเขียนคำถามซ้ำ\n",
    "- ไม่ต้องขึ้นต้นด้วยคำว่า \"คำตอบ:\"\n",
    "- เริ่มต้นด้วยประโยค เช่น \"จากเอกสารที่อ่าน...\" หรือ \"จากข้อมูลที่วิเคราะห์ได้...\"\n",
    "- จากนั้นจัดคำตอบให้อ่านง่ายในรูปแบบข้อ ๆ\n",
    "- มีสรุปท้ายที่ใช้ถ้อยคำกระชับและไม่ซ้ำกับรายละเอียดด้านบน\n",
    "- หลีกเลี่ยงการตอบซ้ำหรือลอกเนื้อหาเดิมซ้ำหลายรอบ\n",
    "\n",
    "ตัวอย่างที่ 1:\n",
    "จากข้อมูลที่วิเคราะห์ได้ สามารถสรุปเกี่ยวกับ Matplotlib ได้ดังนี้:  \n",
    "1. เป็นไลบรารี่ในภาษา Python สำหรับสร้างภาพกราฟ 2 มิติ และ 3 มิติ  \n",
    "2. รองรับการสร้างกราฟเส้น แท่ง วงกลม ฯลฯ  \n",
    "3. ติดตั้งด้วยคำสั่ง pip install matplotlib  \n",
    "4. เรียกใช้งานผ่าน import matplotlib.pyplot as plt  \n",
    "5. ใช้งานง่ายและมีความยืดหยุ่นสูง\n",
    "\n",
    "สรุป: Matplotlib เป็นเครื่องมือช่วยแสดงข้อมูลเป็นภาพได้อย่างมีประสิทธิภาพ เหมาะกับงานวิเคราะห์ทุกรูปแบบ\n",
    "\n",
    "---\n",
    "\n",
    "กรุณาตอบคำถามต่อไปนี้ในรูปแบบเดียวกัน:\n",
    "\"\"\")\n",
    "\n",
    "# สร้าง Prompt ที่สมบูรณ์\n",
    "final_prompt = prompt_template.format(context=context_trimmed, question=question)\n",
    "\n",
    "# ตั้งค่า LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ฟังก์ชันประมวลผลแบบ async\n",
    "async def run_async_query(prompt):\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# ประมวลผลและวัดเวลา\n",
    "start_q = time.perf_counter()\n",
    "response = asyncio.run(run_async_query(final_prompt))\n",
    "end_q = time.perf_counter()\n",
    "response_time_2 = end_q - start_q\n",
    "\n",
    "# แสดงผล\n",
    "# print(\"คำตอบ:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f458a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱ ใช้เวลาในการตอบ: 14.20 วินาที\n"
     ]
    }
   ],
   "source": [
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time_2:.2f} วินาที\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
