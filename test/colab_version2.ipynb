{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd3346b",
   "metadata": {},
   "source": [
    "Description\n",
    "\n",
    "Embedding Model : text-embedding-3-small\n",
    "\n",
    "Vector DB : MongoDB\n",
    "\n",
    "โดยการทดสอบมีวิธีการที่แตกต่างกัน\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58da1f",
   "metadata": {},
   "source": [
    "Pattern 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7198383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from openai import AsyncOpenAI\n",
    "from pymongo import MongoClient\n",
    "import fitz  # PyMuPDF\n",
    "from docx import Document\n",
    "import tiktoken\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddb3d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEY \n",
    "OPENAI_API_KEY : str \n",
    "EMBEDDING : str \n",
    "MONGO_URI : str\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBEDDING = os.getenv(\"EMBEDDING\")\n",
    "client_openai = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "mongo_client = MongoClient(MONGO_URI)\n",
    "db = mongo_client[\"vector_db\"]\n",
    "collection = db[\"vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data\"\n",
    "# 3. Define helper functions\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "async def embed_batch(batch, embed_model):\n",
    "    response = await client_openai.embeddings.create(model=embed_model, input=batch)\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "async def batch_process_embedding_async(text_list, embed_model, batch_size=100):\n",
    "    tasks = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        tasks.append(embed_batch(batch, embed_model))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    embeddings = [embedding for batch in results for embedding in batch]\n",
    "    return embeddings\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def count_tokens(text, model=\"text-embedding-3-small\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23227a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upload เสร็จ 250 records ในเวลา 0.01 วินาที\n",
      "✅ Shape after cleansing: (250, 11)\n"
     ]
    }
   ],
   "source": [
    "start_upload = time.perf_counter()\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(file_path):\n",
    "    full_path = os.path.join(file_path, filename)\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(full_path)\n",
    "        dfs.append(df)\n",
    "    elif filename.endswith('.xlsx'):\n",
    "        df = pd.read_excel(full_path, sheet_name=None)\n",
    "        for sheet in df.values():\n",
    "            dfs.append(sheet)\n",
    "    elif filename.endswith('.docx'):\n",
    "        text = read_docx(full_path)\n",
    "        df = pd.DataFrame({\"text\": [text]})\n",
    "        dfs.append(df)\n",
    "    elif filename.endswith('.pdf'):\n",
    "        text = read_pdf(full_path)\n",
    "        df = pd.DataFrame({\"text\": [text]})\n",
    "        dfs.append(df)\n",
    "\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "df_combined.dropna(inplace=True)\n",
    "df_combined.drop_duplicates(inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "end_upload = time.perf_counter()\n",
    "print(f\"✅ Upload เสร็จ {len(df_combined)} records ในเวลา {end_upload - start_upload:.2f} วินาที\")\n",
    "print(\"✅ Shape after cleansing:\", df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "294c9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "metadata_list = []\n",
    "for i, row in df_combined.iterrows():\n",
    "    metadata = row.to_dict()\n",
    "    text = \"\\n\".join([f\"{k}: {v}\" for k, v in metadata.items()])\n",
    "    texts.append(text)\n",
    "    metadata_list.append((f\"vec-{i}\", metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53dc6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จ 250 records ในเวลา 2.87 วินาที\n"
     ]
    }
   ],
   "source": [
    "start_embed = time.perf_counter()\n",
    "\n",
    "embeddings = await batch_process_embedding_async(texts, EMBEDDING)\n",
    "\n",
    "end_embed = time.perf_counter()\n",
    "embed_time = end_embed - start_embed\n",
    "print(f\"✅ Embedding เสร็จ {len(embeddings)} records ในเวลา {embed_time:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "27a3da0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 250 documents into MongoDB.\n",
      "✅ Upsertเสร็จ 250 records ในเวลา 0.15 วินาที\n"
     ]
    }
   ],
   "source": [
    "start_upsert = time.perf_counter()\n",
    "\n",
    "collection.delete_many({})  \n",
    "documents = []\n",
    "for (vec_id, metadata), embedding, raw_text in zip(metadata_list, embeddings, texts):\n",
    "    documents.append({\n",
    "        \"_id\": vec_id,\n",
    "        \"embedding\": embedding,\n",
    "        \"metadata\": metadata,\n",
    "        \"raw_text\": raw_text\n",
    "    })\n",
    "\n",
    "collection.insert_many(documents)\n",
    "print(f\"✅ Inserted {len(documents)} documents into MongoDB.\")\n",
    "\n",
    "end_upsert = time.perf_counter()\n",
    "upsert_time = end_upsert - start_upsert\n",
    "print(f\"✅ Upsertเสร็จ {len(documents)} records ในเวลา {upsert_time :.2f} วินาที\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce27b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieve_context_from_mongodb(question: str, top_k: int = 50):\n",
    "    embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "    question_vector = embedder.embed_query(question)\n",
    "\n",
    "    documents = list(collection.find())\n",
    "    similarities = []\n",
    "    for doc in documents:\n",
    "        score = cosine_similarity(question_vector, doc[\"embedding\"])\n",
    "        similarities.append((score, doc))\n",
    "\n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_docs = [doc[\"raw_text\"] for score, doc in similarities[:top_k]]\n",
    "    return \"\\n\".join(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b3835ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวน token ทั้งหมดใน context: 3140\n"
     ]
    }
   ],
   "source": [
    "start_q = time.perf_counter()\n",
    "\n",
    "question = \"สินค้ามีอะไรบ้าง และมีจำนวนเท่าไร\"\n",
    "context = await retrieve_context_from_mongodb(question)\n",
    "num_tokens = count_tokens(context)\n",
    "print(f\"จำนวน token ทั้งหมดใน context: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2562ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คำตอบ: จากการวิเคราะห์ข้อมูล พบว่ามีสินค้าทั้งหมด 7 ประเภท ดังนี้:\n",
      "\n",
      "1. T-Shirt จำนวน 3 ตัว\n",
      "2. Laptop จำนวน 14 เครื่อง\n",
      "3. Smartphone จำนวน 4 เครื่อง\n",
      "4. Jeans จำนวน 5 ตัว\n",
      "5. Refrigerator จำนวน 4 เครื่อง\n",
      "6. Washing Machine จำนวน 3 เครื่อง\n",
      "7. Smartwatch จำนวน 5 เครื่อง\n",
      "8. Running Shoes จำนวน 4 คู่\n",
      "\n",
      "ดังนั้น สรุปได้ว่ามีสินค้าทั้งหมด 8 ประเภท และมีจำนวนรวมทั้งสิ้น 42 รายการ\n",
      "⏱ ใช้เวลาในการตอบ: 14.95 วินาที\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "ข้อมูลต่อไปนี้มาจากไฟล์ในรูปแบบตาราง เช่น CSV หรือ Excel ซึ่งอาจมีหลายประเภทข้อมูลและหลายแถว:\n",
    "{context}\n",
    "\n",
    "คำถามของฉันคือ: \"{question}\"\n",
    "\n",
    "กรุณาตอบโดย:\n",
    "- วิเคราะห์ข้อมูลทั้งหมดให้ครบถ้วน\n",
    "- สรุปคำตอบโดยใช้ภาษาธรรมดา ชัดเจน และไม่ใช้การจัดรูปแบบตัวหนา หัวข้อ หรือสัญลักษณ์พิเศษ เช่น ** หรือ -\n",
    "- หากมีหลายรายการสินค้า ให้ระบุชื่อสินค้า พร้อมจำนวน และหน่วยตามลักษณะของสินค้า เช่น เครื่อง, ตัว, คู่, เล่ม ฯลฯ\n",
    "- หากต้องรวมจำนวน ให้รวมและแสดงยอดรวมทั้งหมด\n",
    "- ตอบเป็นภาษาไทยแบบเป็นธรรมชาติ เข้าใจง่าย เหมือนอธิบายให้คนทั่วไปฟัง\n",
    "- หากไม่พบข้อมูลที่เกี่ยวข้อง ให้ตอบว่า \"ไม่พบข้อมูลที่เกี่ยวข้อง\"\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\", api_key=OPENAI_API_KEY)\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "end_q = time.perf_counter()\n",
    "response_time = end_q - start_q\n",
    "print(\"คำตอบ:\", response.content)\n",
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time:.2f} วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "af1cd1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding เสร็จทั้งหมด 250 records ในเวลา 2.87 วินาที\n",
      "✅ Upsert MongoDB เสร็จ 250 vectors ในเวลา 0.15 วินาที\n",
      "⏱ ใช้เวลาในการตอบ: 14.95 วินาที\n",
      "เวลาโดยรวมupload MongoDB ทั้งหมด : 3.01 \n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Embedding เสร็จทั้งหมด {len(embeddings)} records ในเวลา {embed_time:.2f} วินาที\")\n",
    "print(f\"✅ Upsert MongoDB เสร็จ {len(documents)} vectors ในเวลา {upsert_time :.2f} วินาที\")\n",
    "print(f\"⏱ ใช้เวลาในการตอบ: {response_time:.2f} วินาที\")\n",
    "print(f\"เวลาโดยรวมupload MongoDB ทั้งหมด : {embed_time+upsert_time:.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa7f74",
   "metadata": {},
   "source": [
    "Pattern 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "21712bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# compressor = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d5c0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43855efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
